{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark DataFrame\n",
    "* Tabular data\n",
    "  * Rows \n",
    "  * Named Columns\n",
    "* Immutable \n",
    "* Distribute collection of data\n",
    "* Lazy\n",
    "* Can process structured and semi-structured data\n",
    "  * relational database\n",
    "  * csv\n",
    "  * json\n",
    "  * txt\n",
    "  * RDD\n",
    "  * dict\n",
    "  * list\n",
    "  * etc\n",
    "* Support SQL or expression methods\n",
    "  * SELECT * FROM RedWine\n",
    "  * red_wine_df.select()\n",
    "* Schema\n",
    "  * Information about\n",
    "    * column name\n",
    "    * data type\n",
    "    * empty values\n",
    "    * etc\n",
    "  * Help to optimize the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/22 16:46:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/22 16:46:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "master = 'spark://192.168.2.102:7077' # Connect to remote server\n",
    "appName = 'Create DataFrame'\n",
    "\n",
    "conf = SparkConf()\\\n",
    "    .setMaster(master)\\\n",
    "    .setAppName(appName)\\\n",
    "    .set(\"spark.executor.memory\", \"2g\")\\\n",
    "    .set(\"spark.cores.max\", \"4\")\\\n",
    "\n",
    "# RDD\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# DataFrame\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| Id|Value|\n",
      "+---+-----+\n",
      "|  1|    1|\n",
      "|  1|    2|\n",
      "|  2|    3|\n",
      "|  2|    4|\n",
      "+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    {'Id': 1, 'Value': 1},\n",
    "    {'Id': 1, 'Value': 2},\n",
    "    {'Id': 2, 'Value': 3},\n",
    "    {'Id': 2, 'Value': 4},\n",
    "])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| Id|Value|\n",
      "+---+-----+\n",
      "|  1|    1|\n",
      "|  1|    2|\n",
      "|  2|    3|\n",
      "|  2|    4|\n",
      "+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    [1,1],\n",
    "    [1,2],\n",
    "    [2,3],\n",
    "    [2,4],\n",
    "], schema=['Id', 'Value'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create DataFrame from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[7.4, 0.7, 0.0, 5],\n",
       " [7.8, 0.88, 0.0, 5],\n",
       " [7.8, 0.76, 0.04, 5],\n",
       " [11.2, 0.28, 0.56, 6]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine_rdd = sc.parallelize([\n",
    "    [7.4, 0.7, 0.0, 5],\n",
    "    [7.8, 0.88, 0.0, 5],\n",
    "    [7.8, 0.76, 0.04, 5],\n",
    "    [11.2, 0.28, 0.56, 6],\n",
    "])\n",
    "\n",
    "red_wine_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+-------+\n",
      "|fixed acidity|volatile acidity|citric acid|quality|\n",
      "+-------------+----------------+-----------+-------+\n",
      "|          7.4|             0.7|        0.0|      5|\n",
      "|          7.8|            0.88|        0.0|      5|\n",
      "|          7.8|            0.76|       0.04|      5|\n",
      "|         11.2|            0.28|       0.56|      6|\n",
      "+-------------+----------------+-----------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'quality']\n",
    "\n",
    "red_wine_df = spark.createDataFrame(red_wine_rdd, schema=columns)\n",
    "\n",
    "red_wine_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fixed acidity', 'double'),\n",
       " ('volatile acidity', 'double'),\n",
       " ('citric acid', 'double'),\n",
       " ('quality', 'bigint')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|fixed acidity|volatile acidity|citric acid|residual sugar|chlorides|free sulfur dioxide|total sulfur dioxide|density|  pH|sulphates|alcohol|quality|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|          7.4|             0.7|        0.0|           1.9|    0.076|               11.0|                34.0| 0.9978|3.51|     0.56|    9.4|      5|\n",
      "|          7.8|            0.88|        0.0|           2.6|    0.098|               25.0|                67.0| 0.9968| 3.2|     0.68|    9.8|      5|\n",
      "|          7.8|            0.76|       0.04|           2.3|    0.092|               15.0|                54.0|  0.997|3.26|     0.65|    9.8|      5|\n",
      "|         11.2|            0.28|       0.56|           1.9|    0.075|               17.0|                60.0|  0.998|3.16|     0.58|    9.8|      6|\n",
      "|          7.4|             0.7|        0.0|           1.9|    0.076|               11.0|                34.0| 0.9978|3.51|     0.56|    9.4|      5|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "root_path = 'hdfs://192.168.2.102:9000/dataset/{filename}'\n",
    "\n",
    "# By Default inferSchema is False\n",
    "red_wine_df = spark.read.csv(root_path.format(filename='winequality-red.csv'), header=True, inferSchema=False)\n",
    "\n",
    "red_wine_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fixed acidity', 'string'),\n",
       " ('volatile acidity', 'string'),\n",
       " ('citric acid', 'string'),\n",
       " ('residual sugar', 'string'),\n",
       " ('chlorides', 'string'),\n",
       " ('free sulfur dioxide', 'string'),\n",
       " ('total sulfur dioxide', 'string'),\n",
       " ('density', 'string'),\n",
       " ('pH', 'string'),\n",
       " ('sulphates', 'string'),\n",
       " ('alcohol', 'string'),\n",
       " ('quality', 'string')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame from txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|            value|\n",
      "+-----------------+\n",
      "|2021-12-01;1;20.0|\n",
      "|2021-12-02;1;20.2|\n",
      "|    2021-12-03;1;|\n",
      "|2021-12-04;1;20.3|\n",
      "|2021-12-05;1;20.5|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_hist = spark.read.text('data/beer_temp_hist.txt')\n",
    "temp_hist.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-12-01;1;20.0',\n",
       " '2021-12-02;1;20.2',\n",
       " '2021-12-03;1;',\n",
       " '2021-12-04;1;20.3',\n",
       " '2021-12-05;1;20.5']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('data/beer_temp_hist.txt')\n",
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+\n",
      "|      Date|BeerId|Temp|\n",
      "+----------+------+----+\n",
      "|2021-12-01|     1|20.0|\n",
      "|2021-12-02|     1|20.2|\n",
      "|2021-12-03|     1|    |\n",
      "|2021-12-04|     1|20.3|\n",
      "|2021-12-05|     1|20.5|\n",
      "|2021-12-01|     2|16.5|\n",
      "|2021-12-02|     2|16.4|\n",
      "|2021-12-03|     2|16.5|\n",
      "|2021-12-04|     2|    |\n",
      "|2021-12-05|     2|16.8|\n",
      "|2021-12-05|     2|16.7|\n",
      "|2021-12-01|     3|18.3|\n",
      "|2021-12-02|     3|18.4|\n",
      "|2021-12-03|     3|    |\n",
      "|2021-12-01|     4|18.2|\n",
      "+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitted_rows = rdd.map(lambda row: row.split(';'))\n",
    "temp_hist = spark.createDataFrame(splitted_rows, schema=['Date', 'BeerId', 'Temp'])\n",
    "temp_hist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Date', 'string'), ('BeerId', 'string'), ('Temp', 'string')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_hist.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('fixed acidity', 'double'),\n",
       " ('volatile acidity', 'double'),\n",
       " ('citric acid', 'double'),\n",
       " ('residual sugar', 'double'),\n",
       " ('chlorides', 'double'),\n",
       " ('free sulfur dioxide', 'double'),\n",
       " ('total sulfur dioxide', 'double'),\n",
       " ('density', 'double'),\n",
       " ('pH', 'double'),\n",
       " ('sulphates', 'double'),\n",
       " ('alcohol', 'double'),\n",
       " ('quality', 'int')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine_df = spark.read.csv(root_path.format(filename='winequality-red.csv'), header=True, inferSchema=True)\n",
    "red_wine_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import IntegerType, FloatType, DateType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_hist_schema = StructType([\n",
    "    StructField('Date', DateType()),\n",
    "    StructField('BeerId', IntegerType()),\n",
    "    StructField('Temp', FloatType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+\n",
      "|      Date|BeerId|Temp|\n",
      "+----------+------+----+\n",
      "|2021-12-01|     1|20.0|\n",
      "|2021-12-02|     1|20.2|\n",
      "|2021-12-03|     1|null|\n",
      "|2021-12-04|     1|20.3|\n",
      "|2021-12-05|     1|20.5|\n",
      "|2021-12-01|     2|16.5|\n",
      "|2021-12-02|     2|16.4|\n",
      "|2021-12-03|     2|16.5|\n",
      "|2021-12-04|     2|null|\n",
      "|2021-12-05|     2|16.8|\n",
      "|2021-12-05|     2|16.7|\n",
      "|2021-12-01|     3|18.3|\n",
      "|2021-12-02|     3|18.4|\n",
      "|2021-12-03|     3|null|\n",
      "|2021-12-01|     4|18.2|\n",
      "+----------+------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "temp_hist_df = spark.read.csv('data/beer_temp_hist.txt', sep=';', schema=temp_hist_schema)\n",
    "temp_hist_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Date', 'date'), ('BeerId', 'int'), ('Temp', 'float')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_hist_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- BeerId: integer (nullable = true)\n",
      " |-- Temp: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_hist_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
