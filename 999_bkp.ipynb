{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark DataFrame\n",
    "* Tabular data\n",
    "  * Rows \n",
    "  * Named Columns\n",
    "* Immutable \n",
    "* Distribute collection of data\n",
    "* Lazy\n",
    "* Can process structured and semi-structured data\n",
    "  * relational database\n",
    "  * csv\n",
    "  * json\n",
    "  * txt\n",
    "  * RDD\n",
    "  * dict\n",
    "  * list\n",
    "  * etc\n",
    "* Support SQL or expression methods\n",
    "  * SELECT * FROM RedWine\n",
    "  * red_wine_df.select()\n",
    "* Schema\n",
    "  * Information about\n",
    "    * column name\n",
    "    * data type\n",
    "    * empty values\n",
    "    * etc\n",
    "  * Help to optimize the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/22 15:00:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/22 15:00:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "master = 'spark://192.168.2.102:7077' # Connect to remote server\n",
    "appName = 'Create DataFrame'\n",
    "\n",
    "conf = SparkConf()\\\n",
    "    .setMaster(master)\\\n",
    "    .setAppName(appName)\\\n",
    "    .set(\"spark.executor.memory\", \"2g\")\\\n",
    "    .set(\"spark.cores.max\", \"4\")\\\n",
    "\n",
    "# RDD\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# DataFrame\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| Id|Value|\n",
      "+---+-----+\n",
      "|  1|    1|\n",
      "|  1|    2|\n",
      "|  2|    3|\n",
      "|  2|    4|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    {'Id': 1, 'Value': 1},\n",
    "    {'Id': 1, 'Value': 2},\n",
    "    {'Id': 2, 'Value': 3},\n",
    "    {'Id': 2, 'Value': 4},\n",
    "])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| Id|Value|\n",
      "+---+-----+\n",
      "|  1|    1|\n",
      "|  1|    2|\n",
      "|  2|    3|\n",
      "|  2|    4|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    [1,1],\n",
    "    [1,2],\n",
    "    [2,3],\n",
    "    [2,4],\n",
    "], schema=['Id', 'Value'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create DataFrame from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7.4, 0.7, 0.0, 5],\n",
       " [7.8, 0.88, 0.0, 5],\n",
       " [7.8, 0.76, 0.04, 5],\n",
       " [11.2, 0.28, 0.56, 6]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine_rdd = sc.parallelize([\n",
    "    [7.4, 0.7, 0.0, 5],\n",
    "    [7.8, 0.88, 0.0, 5],\n",
    "    [7.8, 0.76, 0.04, 5],\n",
    "    [11.2, 0.28, 0.56, 6],\n",
    "])\n",
    "\n",
    "red_wine_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+-------+\n",
      "|fixed acidity|volatile acidity|citric acid|quality|\n",
      "+-------------+----------------+-----------+-------+\n",
      "|          7.4|             0.7|        0.0|      5|\n",
      "|          7.8|            0.88|        0.0|      5|\n",
      "|          7.8|            0.76|       0.04|      5|\n",
      "|         11.2|            0.28|       0.56|      6|\n",
      "+-------------+----------------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'quality']\n",
    "\n",
    "red_wine_df = spark.createDataFrame(red_wine_rdd, schema=columns)\n",
    "\n",
    "red_wine_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fixed acidity', 'double'),\n",
       " ('volatile acidity', 'double'),\n",
       " ('citric acid', 'double'),\n",
       " ('quality', 'bigint')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'hdfs://192.168.2.102:9000/dataset/{filename}'\n",
    "\n",
    "# By Default inferSchema is False\n",
    "red_wine_df = spark.read.csv(root_path.format(filename='winequality-red.csv'), header=True, inferSchema=False)\n",
    "\n",
    "red_wine_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fixed acidity', 'double'),\n",
       " ('volatile acidity', 'double'),\n",
       " ('citric acid', 'double'),\n",
       " ('residual sugar', 'double'),\n",
       " ('chlorides', 'double'),\n",
       " ('free sulfur dioxide', 'double'),\n",
       " ('total sulfur dioxide', 'double'),\n",
       " ('density', 'double'),\n",
       " ('pH', 'double'),\n",
       " ('sulphates', 'double'),\n",
       " ('alcohol', 'double'),\n",
       " ('quality', 'int')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame from txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|            value|\n",
      "+-----------------+\n",
      "|2021-12-01;1;20.0|\n",
      "|2021-12-02;1;20.2|\n",
      "|    2021-12-03;1;|\n",
      "|2021-12-04;1;20.3|\n",
      "|2021-12-05;1;20.5|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_hist = spark.read.text('data/beer_temp_hist.txt')\n",
    "temp_hist.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-12-01;1;20.0',\n",
       " '2021-12-02;1;20.2',\n",
       " '2021-12-03;1;',\n",
       " '2021-12-04;1;20.3',\n",
       " '2021-12-05;1;20.5']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('data/beer_temp_hist.txt')\n",
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+\n",
      "|      Date|BeerId|Temp|\n",
      "+----------+------+----+\n",
      "|2021-12-01|     1|20.0|\n",
      "|2021-12-02|     1|20.2|\n",
      "|2021-12-03|     1|    |\n",
      "|2021-12-04|     1|20.3|\n",
      "|2021-12-05|     1|20.5|\n",
      "|2021-12-01|     2|16.5|\n",
      "|2021-12-02|     2|16.4|\n",
      "|2021-12-03|     2|16.5|\n",
      "|2021-12-04|     2|    |\n",
      "|2021-12-05|     2|16.8|\n",
      "|2021-12-05|     2|16.7|\n",
      "|2021-12-01|     3|18.3|\n",
      "|2021-12-02|     3|18.4|\n",
      "|2021-12-03|     3|    |\n",
      "|2021-12-01|     4|18.2|\n",
      "+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitted_rows = rdd.map(lambda row: row.split(';'))\n",
    "temp_hist = spark.createDataFrame(splitted_rows, schema=['Date', 'BeerId', 'Temp'])\n",
    "temp_hist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Date', 'string'), ('BeerId', 'string'), ('Temp', 'string')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_hist.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fixed acidity', 'double'),\n",
       " ('volatile acidity', 'double'),\n",
       " ('citric acid', 'double'),\n",
       " ('residual sugar', 'double'),\n",
       " ('chlorides', 'double'),\n",
       " ('free sulfur dioxide', 'double'),\n",
       " ('total sulfur dioxide', 'double'),\n",
       " ('density', 'double'),\n",
       " ('pH', 'double'),\n",
       " ('sulphates', 'double'),\n",
       " ('alcohol', 'double'),\n",
       " ('quality', 'int')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine_df = spark.read.csv(root_path.format(filename='winequality-red.csv'), header=True, inferSchema=True)\n",
    "red_wine_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import IntegerType, FloatType, DateType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_hist_schema = StructType([\n",
    "    StructField('Date', DateType()),\n",
    "    StructField('BeerId', IntegerType()),\n",
    "    StructField('Temp', FloatType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+\n",
      "|      Date|BeerId|Temp|\n",
      "+----------+------+----+\n",
      "|2021-12-01|     1|20.0|\n",
      "|2021-12-02|     1|20.2|\n",
      "|2021-12-03|     1|null|\n",
      "|2021-12-04|     1|20.3|\n",
      "|2021-12-05|     1|20.5|\n",
      "|2021-12-01|     2|16.5|\n",
      "|2021-12-02|     2|16.4|\n",
      "|2021-12-03|     2|16.5|\n",
      "|2021-12-04|     2|null|\n",
      "|2021-12-05|     2|16.8|\n",
      "|2021-12-05|     2|16.7|\n",
      "|2021-12-01|     3|18.3|\n",
      "|2021-12-02|     3|18.4|\n",
      "|2021-12-03|     3|null|\n",
      "|2021-12-01|     4|18.2|\n",
      "+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temp_hist_df = spark.read.csv('data/beer_temp_hist.txt', sep=';', schema=temp_hist_schema)\n",
    "temp_hist_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Date', 'date'), ('BeerId', 'int'), ('Temp', 'float')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_hist_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- BeerId: integer (nullable = true)\n",
      " |-- Temp: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_hist_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Select and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| Id|\n",
      "+---+\n",
      "|  1|\n",
      "|  1|\n",
      "+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bear_id = beer_df.select('Id')\n",
    "bear_id.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------+----------+----+------------------+-----------+--------+\n",
      "| Id|InitialDate|    Type|      Date|   C|                 F|ElapsedDays|FirstDay|\n",
      "+---+-----------+--------+----------+----+------------------+-----------+--------+\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-05|16.7|62.060001373291016|          4|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-05|16.8| 62.23999862670898|          4|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-04|null|              null|          3|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-03|16.5|              61.7|          2|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-02|16.4| 61.51999931335449|          1|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-01|16.5|              61.7|          0|    true|\n",
      "+---+-----------+--------+----------+----+------------------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beer_2 = beer_df.filter(beer_df.Id == 2)\n",
    "beer_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------+----------+----+------------------+-----------+--------+\n",
      "| Id|InitialDate|    Type|      Date|   C|                 F|ElapsedDays|FirstDay|\n",
      "+---+-----------+--------+----------+----+------------------+-----------+--------+\n",
      "|  1| 2021-12-01|   Laget|2021-12-05|20.5|              68.9|          4|   false|\n",
      "|  1| 2021-12-01|   Laget|2021-12-04|20.3| 68.53999862670898|          3|   false|\n",
      "|  1| 2021-12-01|   Laget|2021-12-03|null|              null|          2|   false|\n",
      "|  1| 2021-12-01|   Laget|2021-12-02|20.2| 68.36000137329103|          1|   false|\n",
      "|  1| 2021-12-01|   Laget|2021-12-01|20.0|              68.0|          0|    true|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-05|16.7|62.060001373291016|          4|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-05|16.8| 62.23999862670898|          4|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-04|null|              null|          3|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-03|16.5|              61.7|          2|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-02|16.4| 61.51999931335449|          1|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-01|16.5|              61.7|          0|    true|\n",
      "|  3| 2021-12-01|    null|2021-12-03|null|              null|          2|   false|\n",
      "|  3| 2021-12-01|    null|2021-12-02|18.4|  65.1199993133545|          1|   false|\n",
      "|  3| 2021-12-01|    null|2021-12-01|18.3| 64.93999862670898|          0|    true|\n",
      "|  4| 2021-12-01|     Ipa|2021-12-01|18.2| 64.76000137329102|          0|    true|\n",
      "+---+-----------+--------+----------+----+------------------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beer_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------+----------+----+------------------+-----------+--------+\n",
      "| Id|InitialDate|    Type|      Date|   C|                 F|ElapsedDays|FirstDay|\n",
      "+---+-----------+--------+----------+----+------------------+-----------+--------+\n",
      "|  1| 2021-12-01|   Laget|2021-12-05|20.5|              68.9|          4|   false|\n",
      "|  1| 2021-12-01|   Laget|2021-12-04|20.3| 68.53999862670898|          3|   false|\n",
      "|  1| 2021-12-01|   Laget|2021-12-03|null|              null|          2|   false|\n",
      "|  1| 2021-12-01|   Laget|2021-12-02|20.2| 68.36000137329103|          1|   false|\n",
      "|  1| 2021-12-01|   Laget|2021-12-01|20.0|              68.0|          0|    true|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-05|16.7|62.060001373291016|          4|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-05|16.8| 62.23999862670898|          4|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-04|null|              null|          3|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-03|16.5|              61.7|          2|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-02|16.4| 61.51999931335449|          1|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-01|16.5|              61.7|          0|    true|\n",
      "|  3| 2021-12-01| Unknown|2021-12-03|null|              null|          2|   false|\n",
      "|  3| 2021-12-01| Unknown|2021-12-02|18.4|  65.1199993133545|          1|   false|\n",
      "|  3| 2021-12-01| Unknown|2021-12-01|18.3| 64.93999862670898|          0|    true|\n",
      "|  4| 2021-12-01|     Ipa|2021-12-01|18.2| 64.76000137329102|          0|    true|\n",
      "+---+-----------+--------+----------+----+------------------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beer_df = beer_df.fillna('Unknown', subset=['Type'])\n",
    "beer_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.233333269755047\n",
      "+---+-----------+--------+----------+---------+------------------+-----------+--------+\n",
      "| Id|InitialDate|    Type|      Date|        C|                 F|ElapsedDays|FirstDay|\n",
      "+---+-----------+--------+----------+---------+------------------+-----------+--------+\n",
      "|  1| 2021-12-01|   Laget|2021-12-05|     20.5|              68.9|          4|   false|\n",
      "|  1| 2021-12-01|   Laget|2021-12-04|     20.3| 68.53999862670898|          3|   false|\n",
      "|  1| 2021-12-01|   Laget|2021-12-03|18.233334|              null|          2|   false|\n",
      "|  1| 2021-12-01|   Laget|2021-12-02|     20.2| 68.36000137329103|          1|   false|\n",
      "|  1| 2021-12-01|   Laget|2021-12-01|     20.0|              68.0|          0|    true|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-05|     16.7|62.060001373291016|          4|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-05|     16.8| 62.23999862670898|          4|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-04|18.233334|              null|          3|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-03|     16.5|              61.7|          2|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-02|     16.4| 61.51999931335449|          1|   false|\n",
      "|  2| 2021-12-01|Pale Ale|2021-12-01|     16.5|              61.7|          0|    true|\n",
      "|  3| 2021-12-01| Unknown|2021-12-03|18.233334|              null|          2|   false|\n",
      "|  3| 2021-12-01| Unknown|2021-12-02|     18.4|  65.1199993133545|          1|   false|\n",
      "|  3| 2021-12-01| Unknown|2021-12-01|     18.3| 64.93999862670898|          0|    true|\n",
      "|  4| 2021-12-01|     Ipa|2021-12-01|     18.2| 64.76000137329102|          0|    true|\n",
      "+---+-----------+--------+----------+---------+------------------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean = beer_df.agg(F.mean('C')).collect()[0].asDict()['avg(C)']\n",
    "print(mean)\n",
    "beer_df.fillna(mean, 'C').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:=================================================>    (185 + 5) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------------+------------------+\n",
      "| Id|      Date|                 F|         F[Filled]|\n",
      "+---+----------+------------------+------------------+\n",
      "|  1|2021-12-01|              68.0|              68.0|\n",
      "|  1|2021-12-02| 68.36000137329103| 68.36000137329103|\n",
      "|  1|2021-12-03|              null| 68.36000137329103|\n",
      "|  1|2021-12-04| 68.53999862670898| 68.53999862670898|\n",
      "|  1|2021-12-05|              68.9|              68.9|\n",
      "|  2|2021-12-01|              61.7|              61.7|\n",
      "|  2|2021-12-02| 61.51999931335449| 61.51999931335449|\n",
      "|  2|2021-12-03|              61.7|              61.7|\n",
      "|  2|2021-12-04|              null|              61.7|\n",
      "|  2|2021-12-05|62.060001373291016|62.060001373291016|\n",
      "|  2|2021-12-05| 62.23999862670898| 62.23999862670898|\n",
      "|  3|2021-12-01| 64.93999862670898| 64.93999862670898|\n",
      "|  3|2021-12-02|  65.1199993133545|  65.1199993133545|\n",
      "|  3|2021-12-03|              null|  65.1199993133545|\n",
      "|  4|2021-12-01| 64.76000137329102| 64.76000137329102|\n",
      "+---+----------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "window = Window\\\n",
    "    .partitionBy('Id')\\\n",
    "    .orderBy('Date')\\\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "filled_cols = F.last(beer_df.F, ignorenulls=True).over(window)\n",
    "beer_df = beer_df.withColumn('F[Filled]', filled_cols)\n",
    "\n",
    "beer_df.select(['Id', 'Date', 'F', 'F[Filled]']).orderBy(['Id', 'Date']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:=======================================>              (146 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------------+------------------+\n",
      "| Id|      Date|                 F|         F[Filled]|\n",
      "+---+----------+------------------+------------------+\n",
      "|  1|2021-12-01|              68.0|              68.0|\n",
      "|  1|2021-12-02| 68.36000137329103| 68.36000137329103|\n",
      "|  1|2021-12-03|              null| 68.53999862670898|\n",
      "|  1|2021-12-04| 68.53999862670898| 68.53999862670898|\n",
      "|  1|2021-12-05|              68.9|              68.9|\n",
      "|  2|2021-12-01|              61.7|              61.7|\n",
      "|  2|2021-12-02| 61.51999931335449| 61.51999931335449|\n",
      "|  2|2021-12-03|              61.7|              61.7|\n",
      "|  2|2021-12-04|              null|62.060001373291016|\n",
      "|  2|2021-12-05|62.060001373291016|62.060001373291016|\n",
      "|  2|2021-12-05| 62.23999862670898| 62.23999862670898|\n",
      "|  3|2021-12-01| 64.93999862670898| 64.93999862670898|\n",
      "|  3|2021-12-02|  65.1199993133545|  65.1199993133545|\n",
      "|  3|2021-12-03|              null|              null|\n",
      "|  4|2021-12-01| 64.76000137329102| 64.76000137329102|\n",
      "+---+----------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "window = Window\\\n",
    "    .partitionBy('Id')\\\n",
    "    .orderBy('Date')\\\n",
    "    .rowsBetween(Window.currentRow, Window.unboundedFollowing)\n",
    "\n",
    "filled_cols = F.first(beer_df.F, ignorenulls=True).over(window)\n",
    "beer_df = beer_df.withColumn('F[Filled]', filled_cols)\n",
    "\n",
    "beer_df.select(['Id', 'Date', 'F', 'F[Filled]']).orderBy(['Id', 'Date']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "\n",
    "for i in range(1, 3):\n",
    "    new_col = f'F_-{i}'\n",
    "    cols.append(new_col)\n",
    "\n",
    "    window = Window\\\n",
    "        .partitionBy('Id')\\\n",
    "        .orderBy('Date')\\\n",
    "        .rowsBetween(Window.currentRow -i, Window.currentRow -i)\n",
    "\n",
    "    lag_col = F.first(beer_df['F[Filled]'], ignorenulls=True).over(window)\n",
    "    beer_df = beer_df.withColumn(new_col, lag_col)\n",
    "\n",
    "beer_df.select(['Id', 'Date', 'F[Filled]', *cols]).orderBy(['Id', 'Date']).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
